#WEEK 5 with taddy#
credit <- read.csv("~/Desktop/Data Science/FEM11213/Data/credit.csv",strings=T)
credit[1,]
dim(credit)

## build a design matrix 
library(gamlr)
xcred <- sparse.model.matrix( Default ~ .^2, data=naref(credit))[,-1]
ycred <- credit$Default
# fit the model
credscore <- gamlr(xcred, ycred, family="binomial")
sum(coef(credscore)!=0) 
which.min(AICc(credscore))

## In sample probability estimates
pcred <- drop( predict(credscore, xcred, type="response") )

#png('credFit.png', width=4.5, height=4.5, units="in", res=720)
boxplot(pcred ~ ycred, xlab="Default", ylab="Probability of Default", col=c("pink","dodgerblue"))
#dev.off()

## what are our misclassification rates?
rule <- 1/5 # move this around to see how these change
yhat <- as.numeric(pcred>rule)
table(yhat, ycred)

roc <- function(p,y, ...){
  y <- factor(y)
  n <- length(p)
  p <- as.vector(p)
  Q <- p > matrix(rep(seq(0,1,length=100),n),ncol=100,byrow=TRUE)
  specificity <- colMeans(!Q[y==levels(y)[1],])
  sensitivity <- colMeans(Q[y==levels(y)[2],])
  plot(1-specificity, sensitivity, type="l", ...)
  abline(a=0,b=1,lty=2,col=8)
}
#png('credROC.png', width=4.5, height=4.5, units="in", res=720)
roc(p=pcred, y=ycred, bty="n", main="in-sample")
## our 1/5 rule cutoff
points(x= 1-mean((pcred<.2)[ycred==0]), 
       y=mean((pcred>.2)[ycred==1]), 
       cex=1.5, pch=20, col='red') 
## a standard `max prob' (p=.5) rule
points(x= 1-mean((pcred<.5)[ycred==0]), 
       y=mean((pcred>.5)[ycred==1]), 
       cex=1.5, pch=20, col='blue') 
legend("bottomright",fill=c("red","blue"),
       legend=c("p=1/5","p=1/2"),bty="n",title="cutoff")
#dev.off()

# OOS ROC curve
# refit the model using only 1/2 of data
test <- sample.int(1000,500)
credhalf <- gamlr(xcred[-test,], ycred[-test], family="binomial")
pcredoos <- predict(credhalf, xcred[test,], type="response")
ycredoos <- ycred[test]

## roc curve and fitted distributions
#png('credROCOOS.png', width=4.5, height=4.5, units="in", res=720)
roc(p=pcredoos, y=ycredoos, bty="n", main="out-of-sample")
## our 1/5 rule cutoff
points(x= 1-mean((pcredoos<.2)[ycredoos==0]), 
       y=mean((pcredoos>.2)[ycredoos==1]), 
       cex=1.5, pch=20, col='red') 
## a standard `max prob' (p=.5) rule
points(x= 1-mean((pcredoos<.5)[ycredoos==0]), 
       y=mean((pcredoos>.5)[ycredoos==1]), 
       cex=1.5, pch=20, col='blue') 
#dev.off()

## plot a mosaic
par(mai=c(.8,.8,.1,.1))
plot(factor(Default) ~ history, data=credit, col=c(8,2), ylab="Default")
library(MASS)
data(biopsy)
str(biopsy)

par(mfrow=c(3,3))
for(i in 2:10){
  main<-paste("",colnames(biopsy)[i],"")
  par(mai=c(0.3,0.3,0.4,0.3))
  boxplot(biopsy[,i]~biopsy[,11],ylab="",main=main,col=c("blue","deeppink1"),
          xlab="")
}
# Load the class library for the knn function
library(class)

# Randomly sample 10 rows from the dataset
set.seed(42)  # Ensure reproducibility
test <- sample(1:nrow(fgl), 10)  # Draw a random sample of 10 rows

# Perform k-NN with k=1
nearest1 <- knn(train = x[-test, ], test = x[test, ], cl = fgl$type[-test], k = 1)

# Perform k-NN with k=5
nearest5 <- knn(train = x[-test, ], test = x[test, ], cl = fgl$type[-test], k = 5)

# Combine the results into a data frame
results <- data.frame(
  Actual = fgl$type[test],  # Actual class labels
  Nearest1 = nearest1,      # Predictions with k=1
  Nearest5 = nearest5       # Predictions with k=5
)

# Display the results
print(results)


## confusion matrix for K=10
table(pred=K10,actual=y[test])
install.packages("mlogit")
library(mlogit)
data(Heating)
dim(Heating)
head(Heating, 5)

# create model matrix and pull out response
xH <- model.matrix( depvar ~ ., data=Heating[,-1])[,-1]
yH <- Heating$depvar
table(yH)

# mnlogit in glmnet
library(glmnet)
xfgl <- sparse.model.matrix(type~.*RI, data=fgl)[,-1] #Design matrix includes chemical composition variab gtype <- fgl$type
glassfit <- cv.glmnet(xfgl, gtype, family="multinomial") #cross validation experiments
glassfit
plot(glassfit)
par(mfrow=c(2,3), mai=c(.6,.6,.4,.4))
plot(glassfit$glm, xvar="lambda")
B <- coef(glassfit, select="min"); B
probfgl <- predict(glassfit, xfgl, type="response"); dim(probfgl); head(probfgl,n=2); tail(probfgl,n=2)
probfgl <- drop(probfgl); #use dim(probfgl) to check dim is 214 by 6
n <- nrow(xfgl)
trueclassprobs <- probfgl[cbind(1:n, gtype)]; head(trueclassprobs,n=3); tail(trueclassprobs,n=3)
plot(trueclassprobs ~ gtype, col="lavender", var
     xlab="glass type", ylab="prob( true class )")
